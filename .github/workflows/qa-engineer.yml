name: AI QA Engineer

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to test (optional, defaults to PR preview URL)'
        required: false
        type: string
      focus:
        description: 'Focus area (optional): accessibility, performance, forms, mobile, all'
        required: false
        type: string
        default: 'all'

permissions:
  contents: read
  pull-requests: write
  issues: write

env:
  NODE_VERSION: '20'
  PLAYWRIGHT_VERSION: '1.48.0'

jobs:
  qa-test:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci
        env:
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: 'true'

      - name: Install Playwright Browsers
        run: npx playwright install chromium --with-deps
        # Cache Playwright browsers to avoid re-downloading
        shell: bash

      - name: Cache Playwright Browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ env.PLAYWRIGHT_VERSION }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Wait for Preview Deployment
        id: preview
        if: github.event_name == 'pull_request'
        timeout-minutes: 5
        run: |
          # Set preview URL - customize based on your platform
          # Examples:
          # Vercel: https://${{ github.event.repository.name }}-git-${{ github.head_ref }}-${{ github.repository_owner }}.vercel.app
          # Netlify: https://deploy-preview-${{ github.event.number }}--your-site.netlify.app
          # GitHub Pages: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}

          PREVIEW_URL="${{ inputs.url || format('https://{0}.github.io/{1}', github.repository_owner, github.event.repository.name) }}"
          echo "preview_url=$PREVIEW_URL" >> $GITHUB_OUTPUT
          echo "Testing URL: $PREVIEW_URL"

          # Smart deployment wait: poll for HTTP 200 or timeout
          echo "Waiting for preview deployment to be ready..."
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if curl -s -f -o /dev/null -w "%{http_code}" "$PREVIEW_URL" | grep -q "200"; then
              echo "âœ“ Preview deployment is ready!"
              exit 0
            fi
            attempt=$((attempt + 1))
            echo "Attempt $attempt/$max_attempts: Waiting for deployment..."
            sleep 5
          done

          echo "âš ï¸  Preview deployment not ready after ${max_attempts}*5 seconds, continuing anyway..."
          exit 0

      - name: Create Screenshots Directory
        run: mkdir -p screenshots

      - name: Run AI QA Engineer
        id: qa-run
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          TEST_URL: ${{ steps.preview.outputs.preview_url || inputs.url }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          TEST_FOCUS: ${{ inputs.focus || 'all' }}
        run: |
          echo "::group::QA Testing Configuration"
          echo "URL: $TEST_URL"
          echo "Focus Area: $TEST_FOCUS"
          echo "PR Number: $PR_NUMBER"
          echo "::endgroup::"

          echo "::group::Starting AI QA Engineer"
          START_TIME=$(date +%s)

          npx claude-code --print \
            --mcp-config .claude/mcp-config.json \
            --system-prompt "$(cat .claude/qa-engineer-prompt.md)" \
            "Test the website at $TEST_URL

             ## Test Configuration
             - Focus area: $TEST_FOCUS
             - PR Number: $PR_NUMBER

             ## Required Testing

             ### 1. Network & Console Health (First!)
             Before any visual testing:
             - Monitor for failed network requests (4xx, 5xx errors)
             - Monitor for console errors and warnings
             - Note any slow API calls (>3 seconds)
             - Check for missing resources (404s)

             ### 2. Viewport Testing
             Test on these viewports:
             - Mobile: 375x667 (iPhone SE)
             - Tablet: 768x1024 (iPad)
             - Desktop: 1920x1080 (Full HD)

             ### 3. Functional Testing
             - Test all interactive elements (buttons, links, forms)
             - Test navigation flows
             - Test any dynamic content loading
             - Try to break things - rapid clicks, edge cases

             ### 4. Visual Testing
             - Check for layout issues, overflow, cut-off text
             - Verify responsive design works across viewports
             - Check alignment and spacing

             ### 5. Accessibility
             - Tab navigation works
             - Focus states visible
             - Images have alt text

             ## Output Requirements

             1. Save screenshots to ./screenshots/ directory
             2. Create qa-report.md with:
                - Summary (bugs found, severity breakdown)
                - Network health section
                - Console output section
                - Detailed bug reports with steps to reproduce
                - Screenshots referenced by filename
                - Recommendations prioritized by impact

             Be thorough. Think like a user who wants to break things." || {
            echo "âš ï¸ QA testing encountered an error"
            exit 1
          }

          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          echo "âœ“ QA testing completed in ${DURATION}s"
          echo "::endgroup::"
          echo "qa_duration_seconds=$DURATION" >> $GITHUB_OUTPUT

      - name: Upload Screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: qa-screenshots-${{ github.run_number }}
          path: screenshots/
          retention-days: 14
          if-no-files-found: ignore

      - name: Upload QA Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: qa-report-${{ github.run_number }}
          path: qa-report.md
          retention-days: 14
          if-no-files-found: ignore

      - name: Post QA Report to PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        env:
          QA_DURATION: ${{ steps.qa-run.outputs.qa_duration_seconds || '0' }}
        with:
          script: |
            const fs = require('fs');

            let report = '## ðŸ” AI QA Engineer Report\n\n';

            if (fs.existsSync('qa-report.md')) {
              const content = fs.readFileSync('qa-report.md', 'utf8');
              report += content;

              // Add artifacts link
              report += '\n\n### ðŸ“Ž Artifacts\n';
              report += `- [Screenshots](../actions/runs/${{ github.run_id }})\n`;
              report += `- [Full Report](../actions/runs/${{ github.run_id }})\n`;
            } else {
              report += 'âš ï¸ QA report was not generated. Check the [workflow logs](../actions/runs/${{ github.run_id }}) for details.';
            }

            // Add metrics section
            report += '\n\n### ðŸ“Š Metrics\n';
            const duration = parseInt(process.env.QA_DURATION) || 0;
            report += `- Test Duration: ${duration}s\n`;

            // Estimate cost (Claude API pricing example)
            const estimatedCost = (0.005 * duration / 60).toFixed(4);
            report += `- Estimated Cost: $${estimatedCost}\n`;
            report += `- Run ID: ${{ github.run_id }}\n`;

            report += '\n\n---\n';
            report += '*Automated testing by [AI QA Engineer](https://github.com/tyler-james-bridges/ai-qa-engineer) using Claude Code + Playwright*';

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.body.includes('AI QA Engineer Report')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: report
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: report
              });
            }
